
    util seq(funcs, done) should return a function that runs asynchronous functions in funcs in order: [2K[0G  â€¤ util seq(funcs, done) should return a function that runs asynchronous functions in funcs in order
    util seq(funcs, done) should handle errors by calling done with the error: [2K[0G  â€¤ util seq(funcs, done) should handle errors by calling done with the error
    util seq(funcs, done) should handle exceptions thrown by functions by calling done with the exception: [2K[0G  â€¤ util seq(funcs, done) should handle exceptions thrown by functions by calling done with the exception
    util seq(funcs, done) should call done with no error if all is successful: [2K[0G  â€¤ util seq(funcs, done) should call done with no error if all is successful
    util seq(funcs, done) _.to(names...) should return a function that places the corresponding arguments in "this" (skipping err): [2K[0G  â€¤ util seq(funcs, done) _.to(names...) should return a function that places the corresponding arguments in "this" (skipping err)
    util timeUid() should return a unique string: [2K[0G  â€¤ util timeUid() should return a unique string
    util timeUid() should return a larger value when called over one millisecond later: [2K[0G  â€¤ util timeUid() should return a larger value when called over one millisecond later
    util Encoder(allowedSpecial) .encode(str) should encode str in a way that will only include letters, digits or characters from allowedSpecial: [2K[0G  â€¤ util Encoder(allowedSpecial) .encode(str) should encode str in a way that will only include letters, digits or characters from allowedSpecial
    util Encoder(allowedSpecial) .encode(str) should throw an exception if less than three special characters are allowed: [2K[0G  â€¤ util Encoder(allowedSpecial) .encode(str) should throw an exception if less than three special characters are allowed
    util Encoder(allowedSpecial) .decode(enc) should decode a string encoded with .encode(): [2K[0G  â€¤ util Encoder(allowedSpecial) .decode(enc) should decode a string encoded with .encode()
    util parallel(n, callback) should return a callback function that will call "callback" after it has been called n times: [2K[0G  â€¤ util parallel(n, callback) should return a callback function that will call "callback" after it has been called n times
    util parallel(n, callback) should call the callback immediately with an error if an error is given to the parallel callback: [2K[0G  â€¤ util parallel(n, callback) should call the callback immediately with an error if an error is given to the parallel callback
    util Worker should call a given function iteratively, in given intervals, until stopped: [2K[0G  â€¤ util Worker should call a given function iteratively, in given intervals, until stopped
    util Worker should assure that no more than a given number of instances of the function are running at any given time: [2K[0G  â€¤ util Worker should assure that no more than a given number of instances of the function are running at any given time
    jsMapper should receive a javascript function as the mapping's "func" field and call it with the entry as its "this": [2K[0G  â€¤ jsMapper should receive a javascript function as the mapping's "func" field and call it with the entry as its "this"
    jsMapper should pass the function the path and the content to be mapped: [2K[0G  â€¤ jsMapper should pass the function the path and the content to be mapped
    jsMapper should provide an emit() function that contributes content actions to the output: [2K[0G  â€¤ jsMapper should provide an emit() function that contributes content actions to the output
    MatchMaker should proxy transactions to the underlying storage: [2K[0G  â€¤ MatchMaker should proxy transactions to the underlying storage
    MatchMaker put should add a _tasks entry to the result, containing a list of mappings: [2K[0G  â€¤ MatchMaker put should add a _tasks entry to the result, containing a list of mappings
    MatchMaker put should add a mapping entry for each .map file in the directory when adding a .json file: [2K[0G  â€¤ MatchMaker put should add a mapping entry for each .map file in the directory when adding a .json file
    MatchMaker put should add a mapping entry for each .json file in the directory when adding a .map file: [2K[0G  â€¤ MatchMaker put should add a mapping entry for each .json file in the directory when adding a .map file
    MatchMaker put should increment a counter (dir_exists) in the directory, so that it is only zero if the directory is new: [2K[0G  â€¤ MatchMaker put should increment a counter (dir_exists) in the directory, so that it is only zero if the directory is new
    MatchMaker put should create a transaction entry in the _tasks field of the result to add a .d entry in the parent directory if the directory is new: [2K[0G  â€¤ MatchMaker put should create a transaction entry in the _tasks field of the result to add a .d entry in the parent directory if the directory is new
    MatchMaker put should create a task for each subdirectory, to propagate .map files up: [2K[0G  â€¤ MatchMaker put should create a task for each subdirectory, to propagate .map files up
    MatchMaker put should create an unmap task for the old content of a file when modifying an existing .json file: [2K[0G  â€¤ MatchMaker put should create an unmap task for the old content of a file when modifying an existing .json file
    MatchMaker put should create an unmap task for the old content of a file when modifying an existing .map file: [2K[0G  â€¤ MatchMaker put should create an unmap task for the old content of a file when modifying an existing .map file
    MatchMaker remove should create an unmap task for each removed .json file, for each existing .map file: [2K[0G  â€¤ MatchMaker remove should create an unmap task for each removed .json file, for each existing .map file
    MatchMaker remove should create an unmap task for each removed .map file, for each existing .json file: [2K[0G  â€¤ MatchMaker remove should create an unmap task for each removed .map file, for each existing .json file
    MongoFS as StorageDriver should support any kind of characters in paths, with the exception that slash (/) and star (*): [2K[0G  â€¤ MongoFS as StorageDriver should support any kind of characters in paths, with the exception that slash (/) and star (*)
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) should allow for multiple get and put operations to be performed atomically: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) should allow for multiple get and put operations to be performed atomically
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) should retrieve the value with the highest _ts value: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) should retrieve the value with the highest _ts value
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should retrieve the value of a file: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should retrieve the value of a file
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should retrieve the latest version prior to the transaction timestamp if one is stored: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should retrieve the latest version prior to the transaction timestamp if one is stored
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should retrieve the earliest stored version if latest prior to ts is not stored: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should retrieve the earliest stored version if latest prior to ts is not stored
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should not find the file if it was created past the transaction ts, as long as enough versions are stored: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should not find the file if it was created past the transaction ts, as long as enough versions are stored
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should return all files if given *: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should return all files if given *
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should return all files which names end with .<suffix>, if given *.<suffix>: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should return all files which names end with .<suffix>, if given *.<suffix>
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) put should write a file so that "get" retrieves it: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) put should write a file so that "get" retrieves it
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) put should assign a timestamp to a file if one is not provided: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) put should assign a timestamp to a file if one is not provided
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) put should reflect the provided timestamp if one is given: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) put should reflect the provided timestamp if one is given
  - MongoFS as StorageDriver .transaction(trans, callback(err, result)) map should emit actions including the mapping for all files in the directory
  - MongoFS as StorageDriver .transaction(trans, callback(err, result)) map should emit actions so that when sending the "tramp" actions back, we get mappings for all files in the sub-tree
  - MongoFS as StorageDriver .transaction(trans, callback(err, result)) map should work whether or not the directory already exists
  - MongoFS as StorageDriver .transaction(trans, callback(err, result)) map should propagate to future subdirectories
  - MongoFS as StorageDriver .transaction(trans, callback(err, result)) map with put should cause subsequent puts emit the mapping for the new object
  - MongoFS as StorageDriver .transaction(trans, callback(err, result)) map with put should cause puts that overrides an existing value provide mapping for the new value and unmapping for the old one
  - MongoFS as StorageDriver .transaction(trans, callback(err, result)) map with remove should emit unmapping of the removed content
  - MongoFS as StorageDriver .transaction(trans, callback(err, result)) unmap should remove the mapping with ts from path, and produce actions to undo its effect
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) remove should remove a file of the given path: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) remove should remove a file of the given path
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) remove should remove a file only if the removal timestamp is greater than the latest: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) remove should remove a file only if the removal timestamp is greater than the latest
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) getIfExists should return only the files that exist in the list: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) getIfExists should return only the files that exist in the list
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) getIfExists should handle wildcards, just like "get", and succeed even if a file does not exist: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) getIfExists should handle wildcards, just like "get", and succeed even if a file does not exist
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) tsCond should cause the transaction to be canceled if one of the given files does not have the corresponding ts value: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) tsCond should cause the transaction to be canceled if one of the given files does not have the corresponding ts value
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) tsCond should allow the transaction to happen if the timestamps are accurate: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) tsCond should allow the transaction to happen if the timestamps are accurate
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) accum should create files containing numbers, when given names that do not exist: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) accum should create files containing numbers, when given names that do not exist
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) accum should add the given number to each file, and emit the previous value: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) accum should add the given number to each file, and emit the previous value
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) accumReset should reset the given accumulators, so that subsequent reads receive 0: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) accumReset should reset the given accumulators, so that subsequent reads receive 0
  - Dispatcher .transaction(trans, callback(err, actions)) should handle transactions that do not require futher action by forwaring them to storage
  - Dispatcher .transaction(trans, callback(err, actions)) should write actions that require further treatment to the tracker, in a path provided by the scheduler
  - Dispatcher .tick(path, callback(err, job)) should select a pending task from the tracker, mark it in progress and emit it in the callback
  - Dispatcher .tick(path, callback(err, job)) should select a different job on each call
  - Dispatcher .tick(path, callback(err, job)) should emit undefined as a job if no job is found
  - Dispatcher .tick(path, callback(err, job)) should take the path from the scheduler if not provided
  - Dispatcher tock(job, callback(err)) should perform the given job
  - Dispatcher .start() and .stop() should cause the dispatcher to automatically take tasks and execute them
  - Dispatcher .wait(ts, callback(err)) should trigger the callback after all work related to this ts has been complete
  - Dispatcher mapping should handle map operations with _mapping fields containing HTTP URLs by redirecting them to RESTful mappers
  - Dispatcher mapping should handle map operations with _mapping="mirror" by mirrorring data
  - Dispatcher mapping should handle unmap operations by removing mirrored data
  - Dispatcher mapping should support the javascript mapper
  - Dispatcher mapping should treat mapping results for which the path is a directory, as new mappings
  - Dispatcher mapping should unmap when a file creating a mapping, is removed
    MirrorMapper should returns content objects identical to the source, except changing the path: [2K[0G  â€¤ MirrorMapper should returns content objects identical to the source, except changing the path
  - lookingGlass RESTful API PUT should stopre JSON object so that GET can retrieve them
  - lookingGlass RESTful API PUT should accept data of any content type
  - lookingGlass RESTful API GET should return a status of 404 when accessing a file that does not exist
  - lookingGlass RESTful API GET should return files stored with any content type, providing the content type given at storage
  - lookingGlass RESTful API GET should retrieve the content of a directory, if the path ends with a slash
  - lookingGlass RESTful API GET should provide timestamps for each file when retrieving a directory
  - lookingGlass RESTful API DELETE should remove a file as response to a DELETE request
  - lookingGlass RESTful API POST should perform the transaction enclosed in the body of the request

  50 passing (599 ms)
  31 pending

