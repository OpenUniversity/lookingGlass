
    util seq(funcs, done) should return a function that runs asynchronous functions in funcs in order: [2K[0G  â€¤ util seq(funcs, done) should return a function that runs asynchronous functions in funcs in order
    util seq(funcs, done) should handle errors by calling done with the error: [2K[0G  â€¤ util seq(funcs, done) should handle errors by calling done with the error
    util seq(funcs, done) should handle exceptions thrown by functions by calling done with the exception: [2K[0G  â€¤ util seq(funcs, done) should handle exceptions thrown by functions by calling done with the exception
    util seq(funcs, done) should call done with no error if all is successful: [2K[0G  â€¤ util seq(funcs, done) should call done with no error if all is successful
    util seq(funcs, done) _.to(names...) should return a function that places the corresponding arguments in "this" (skipping err): [2K[0G  â€¤ util seq(funcs, done) _.to(names...) should return a function that places the corresponding arguments in "this" (skipping err)
    util timeUid() should return a unique string: [2K[0G  â€¤ util timeUid() should return a unique string
    util timeUid() should return a larger value when called over one millisecond later: [2K[0G  â€¤ util timeUid() should return a larger value when called over one millisecond later
    util Encoder(allowedSpecial) .encode(str) should encode str in a way that will only include letters, digits or characters from allowedSpecial: [2K[0G  â€¤ util Encoder(allowedSpecial) .encode(str) should encode str in a way that will only include letters, digits or characters from allowedSpecial
    util Encoder(allowedSpecial) .encode(str) should throw an exception if less than three special characters are allowed: [2K[0G  â€¤ util Encoder(allowedSpecial) .encode(str) should throw an exception if less than three special characters are allowed
    util Encoder(allowedSpecial) .decode(enc) should decode a string encoded with .encode(): [2K[0G  â€¤ util Encoder(allowedSpecial) .decode(enc) should decode a string encoded with .encode()
    util parallel(n, callback) should return a callback function that will call "callback" after it has been called n times: [2K[0G  â€¤ util parallel(n, callback) should return a callback function that will call "callback" after it has been called n times
    util parallel(n, callback) should call the callback immediately with an error if an error is given to the parallel callback: [2K[0G  â€¤ util parallel(n, callback) should call the callback immediately with an error if an error is given to the parallel callback
    util Worker should call a given function iteratively, in given intervals, until stopped: [2K[0G  â€¤ util Worker should call a given function iteratively, in given intervals, until stopped
    util Worker should assure that no more than a given number of instances of the function are running at any given time: [2K[0G  â€¤ util Worker should assure that no more than a given number of instances of the function are running at any given time
    jsMapper should receive a javascript function as the mapping's "func" field and call it with the entry as its "this": [2K[0G  â€¤ jsMapper should receive a javascript function as the mapping's "func" field and call it with the entry as its "this"
    jsMapper should pass the function the path and the content to be mapped: [2K[0G  â€¤ jsMapper should pass the function the path and the content to be mapped
    jsMapper should provide an emit() function that contributes content actions to the output: [2K[0G  â€¤ jsMapper should provide an emit() function that contributes content actions to the output
    MatchMaker should proxy transactions to the underlying storage: [2K[0G  â€¤ MatchMaker should proxy transactions to the underlying storage
    MatchMaker put should add a _tasks entry to the result, containing a list of mappings: [2K[0G  â€¤ MatchMaker put should add a _tasks entry to the result, containing a list of mappings
    MatchMaker put should add a mapping entry for each .map file in the directory when adding a .json file: [2K[0G  â€¤ MatchMaker put should add a mapping entry for each .map file in the directory when adding a .json file
    MatchMaker put should add a mapping entry for each .json file in the directory when adding a .map file: [2K[0G  â€¤ MatchMaker put should add a mapping entry for each .json file in the directory when adding a .map file
    MatchMaker put should increment a counter (dir_exists) in the directory, so that it is only zero if the directory is new: [2K[0G  â€¤ MatchMaker put should increment a counter (dir_exists) in the directory, so that it is only zero if the directory is new
    MatchMaker put should create a transaction entry in the _tasks field of the result to add a .d entry in the parent directory if the directory is new: [2K[0G  â€¤ MatchMaker put should create a transaction entry in the _tasks field of the result to add a .d entry in the parent directory if the directory is new
    MatchMaker put should create a task for each subdirectory, to propagate .map files up: [2K[0G  â€¤ MatchMaker put should create a task for each subdirectory, to propagate .map files up
    MatchMaker put should create a task for propagating .map files to a new directory when a .d file is added: [2K[0G  â€¤ MatchMaker put should create a task for propagating .map files to a new directory when a .d file is added
    MatchMaker put should create an unmap task for the old content of a file when modifying an existing .json file: [2K[0G  â€¤ MatchMaker put should create an unmap task for the old content of a file when modifying an existing .json file
    MatchMaker put should create an unmap task for the old content of a file when modifying an existing .map file: [2K[0G  â€¤ MatchMaker put should create an unmap task for the old content of a file when modifying an existing .map file
    MatchMaker put should support the case where the .map and .json files are introduced in order opposite to their timestamps: [2K[0G  â€¤ MatchMaker put should support the case where the .map and .json files are introduced in order opposite to their timestamps
    MatchMaker remove should create an unmap task for each removed .json file, for each existing .map file: [2K[0G  â€¤ MatchMaker remove should create an unmap task for each removed .json file, for each existing .map file
    MatchMaker remove should create an unmap task for each removed .map file, for each existing .json file: [2K[0G  â€¤ MatchMaker remove should create an unmap task for each removed .map file, for each existing .json file
    MatchMaker remove should create transaction tasks to remove .map files from child directories, when a .map file is removed: [2K[0G  â€¤ MatchMaker remove should create transaction tasks to remove .map files from child directories, when a .map file is removed
    MongoFS as StorageDriver should support any kind of characters in paths, with the exception that slash (/) and star (*): [2K[0G  â€¤ MongoFS as StorageDriver should support any kind of characters in paths, with the exception that slash (/) and star (*)
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) should allow for multiple get and put operations to be performed atomically: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) should allow for multiple get and put operations to be performed atomically
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) should retrieve the value with the highest _ts value: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) should retrieve the value with the highest _ts value
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should retrieve the value of a file: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should retrieve the value of a file
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should retrieve the latest version prior to the transaction timestamp if one is stored: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should retrieve the latest version prior to the transaction timestamp if one is stored
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should retrieve the earliest stored version if latest prior to ts is not stored: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should retrieve the earliest stored version if latest prior to ts is not stored
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should not find the file if it was created past the transaction ts, as long as enough versions are stored: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should not find the file if it was created past the transaction ts, as long as enough versions are stored
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should return all files if given *: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should return all files if given *
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should return all files which names end with .[suffix], if given *.[suffix]: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should return all files which names end with .[suffix], if given *.[suffix]
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should not return deleted files in wildcard searches: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) get should not return deleted files in wildcard searches
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) put should write a file so that "get" retrieves it: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) put should write a file so that "get" retrieves it
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) put should assign a timestamp to a file if one is not provided: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) put should assign a timestamp to a file if one is not provided
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) put should reflect the provided timestamp if one is given: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) put should reflect the provided timestamp if one is given
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) remove should remove a file of the given path: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) remove should remove a file of the given path
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) remove should remove a file only if the removal timestamp is greater than the latest: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) remove should remove a file only if the removal timestamp is greater than the latest
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) getIfExists should return only the files that exist in the list: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) getIfExists should return only the files that exist in the list
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) getIfExists should handle wildcards, just like "get", and succeed even if a file does not exist: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) getIfExists should handle wildcards, just like "get", and succeed even if a file does not exist
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) getLatest should return the latest version of each file, regardless of the transaction timestamp: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) getLatest should return the latest version of each file, regardless of the transaction timestamp
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) tsCond should cause the transaction to be canceled if one of the given files does not have the corresponding ts value: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) tsCond should cause the transaction to be canceled if one of the given files does not have the corresponding ts value
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) tsCond should allow the transaction to happen if the timestamps are accurate: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) tsCond should allow the transaction to happen if the timestamps are accurate
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) accum should create files containing numbers, when given names that do not exist: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) accum should create files containing numbers, when given names that do not exist
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) accum should add the given number to each file, and emit the previous value: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) accum should add the given number to each file, and emit the previous value
    MongoFS as StorageDriver .transaction(trans, callback(err, result)) accumReset should reset the given accumulators, so that subsequent reads receive 0: [2K[0G  â€¤ MongoFS as StorageDriver .transaction(trans, callback(err, result)) accumReset should reset the given accumulators, so that subsequent reads receive 0
    Dispatcher transaction(trans, callback(err, result)) should proxy transactions to the underlying layer: [2K[0G  â€¤ Dispatcher transaction(trans, callback(err, result)) should proxy transactions to the underlying layer
    Dispatcher dispatch(task, callback(err, tasks)) transaction should handle "transaction" tasks by performing a transaction on the storage: [2K[0G  â€¤ Dispatcher dispatch(task, callback(err, tasks)) transaction should handle "transaction" tasks by performing a transaction on the storage
    Dispatcher dispatch(task, callback(err, tasks)) transaction should return any further tasks: [2K[0G  â€¤ Dispatcher dispatch(task, callback(err, tasks)) transaction should return any further tasks
    Dispatcher dispatch(task, callback(err, tasks)) map should be referred to the corresponding mapper, returning transactions with put operations: [2K[0G  â€¤ Dispatcher dispatch(task, callback(err, tasks)) map should be referred to the corresponding mapper, returning transactions with put operations
    Dispatcher dispatch(task, callback(err, tasks)) map should return an accum transaction, if the mapper returns content as a number: [2K[0G  â€¤ Dispatcher dispatch(task, callback(err, tasks)) map should return an accum transaction, if the mapper returns content as a number
    Dispatcher dispatch(task, callback(err, tasks)) unmap should be referred to the corresponding mapper, returning transactions with remove operations: [2K[0G  â€¤ Dispatcher dispatch(task, callback(err, tasks)) unmap should be referred to the corresponding mapper, returning transactions with remove operations
    Dispatcher dispatch(task, callback(err, tasks)) unmap should return an accum transaction with negative increment, if the mapper returns content as a number: [2K[0G  â€¤ Dispatcher dispatch(task, callback(err, tasks)) unmap should return an accum transaction with negative increment, if the mapper returns content as a number
    ClusterNode transaction(trans, callback(err, result)) should relay the transaction to the underlying storage (regardless of node): [2K[0G  â€¤ ClusterNode transaction(trans, callback(err, result)) should relay the transaction to the underlying storage (regardless of node)
    ClusterNode transaction(trans, callback(err, result)) should write returned tasks to the tracker, in the form: /node/[nodeID]/[taskID].pending: [2K[0G  â€¤ ClusterNode transaction(trans, callback(err, result)) should write returned tasks to the tracker, in the form: /node/[nodeID]/[taskID].pending
    ClusterNode start() should cause the node to automatically take .pending tasks and execute them: [2K[0G  â€¤ ClusterNode start() should cause the node to automatically take .pending tasks and execute them
    ClusterNode wait(tracking, callback(err)) should call the callback once all processing for the transaction associated with the tracking object is done: [2K[0G  â€¤ ClusterNode wait(tracking, callback(err)) should call the callback once all processing for the transaction associated with the tracking object is done
    Trampoline transaction should relay transactions to the underlying storage, and return the result: [2K[0G  â€¤ Trampoline transaction should relay transactions to the underlying storage, and return the result
    Trampoline transaction should perform subsequent tasks before calling the callback, given the timeout is not exceeded: [2K[0G  â€¤ Trampoline transaction should perform subsequent tasks before calling the callback, given the timeout is not exceeded
    Trampoline transaction should not exceed the given timeout (by too much): [2K[0G  â€¤ Trampoline transaction should not exceed the given timeout (by too much)
    Trampoline transaction should update result._tasks so that the residual tasks can be resumed once the timeout was exceeded: [2K[0G  â€¤ Trampoline transaction should update result._tasks so that the residual tasks can be resumed once the timeout was exceeded
    Trampoline dispatch should relay tasks to the underlying dispatcher: [2K[0G  â€¤ Trampoline dispatch should relay tasks to the underlying dispatcher
    Trampoline dispatch should re-dispatch tasks returned from dispatched tasks, until no tasks are left, given it is done within the timeout: [2K[0G  â€¤ Trampoline dispatch should re-dispatch tasks returned from dispatched tasks, until no tasks are left, given it is done within the timeout
    MirrorMapper should returns content objects identical to the source, except changing the path: [2K[0G  â€¤ MirrorMapper should returns content objects identical to the source, except changing the path
  - lookingGlass RESTful API PUT should stopre JSON object so that GET can retrieve them
  - lookingGlass RESTful API PUT should accept data of any content type
  - lookingGlass RESTful API GET should return a status of 404 when accessing a file that does not exist
  - lookingGlass RESTful API GET should return files stored with any content type, providing the content type given at storage
  - lookingGlass RESTful API GET should retrieve the content of a directory, if the path ends with a slash
  - lookingGlass RESTful API GET should provide timestamps for each file when retrieving a directory
  - lookingGlass RESTful API DELETE should remove a file as response to a DELETE request
  - lookingGlass RESTful API POST should perform the transaction enclosed in the body of the request

  72 passing (965 ms)
  8 pending

